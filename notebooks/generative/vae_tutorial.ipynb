{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE) Tutorial\n",
    "\n",
    "This notebook demonstrates VAE for generative modeling on MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.generative import VAE, VAETrainer\n",
    "from src.utils import load_mnist, get_device, set_seed, plot_training_curves, plot_image_grid, plot_reconstruction\n",
    "\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "train_loader = load_mnist(batch_size=128, train=True, download=True)\n",
    "test_loader = load_mnist(batch_size=128, train=False, download=True)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE model\n",
    "model = VAE(\n",
    "    input_dim=784,  # 28x28 images flattened\n",
    "    latent_dim=20,\n",
    "    hidden_dims=[256, 128]\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = VAETrainer(model, device=device)\n",
    "history = trainer.train(\n",
    "    train_loader,\n",
    "    n_epochs=10,\n",
    "    learning_rate=1e-3,\n",
    "    val_loader=test_loader,\n",
    "    beta=1.0,  # beta-VAE parameter\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plot_training_curves(history['train_losses'], history['val_losses'], title='VAE Loss Curves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "dataiter = iter(test_loader)\n",
    "images, _ = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "# Reconstruct images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images_flat = images.view(images.size(0), -1)\n",
    "    # Normalize to [0, 1]\n",
    "    images_flat = (images_flat - images_flat.min()) / (images_flat.max() - images_flat.min())\n",
    "    reconstructed, _, _ = model(images_flat)\n",
    "    reconstructed = reconstructed.view(-1, 1, 28, 28)\n",
    "\n",
    "# Plot original vs reconstructed\n",
    "plot_reconstruction(images[:8], reconstructed[:8], n_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the latent space\n",
    "n_samples = 32\n",
    "samples = model.sample(n_samples, device=device)\n",
    "samples = samples.view(-1, 1, 28, 28)\n",
    "\n",
    "# Plot generated samples\n",
    "plot_image_grid(samples, n_rows=4, n_cols=8, title='Generated Samples from VAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test data to visualize latent space\n",
    "model.eval()\n",
    "latent_vectors = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        images_flat = images.view(images.size(0), -1)\n",
    "        images_flat = (images_flat - images_flat.min()) / (images_flat.max() - images_flat.min())\n",
    "        \n",
    "        mu, _ = model.encode(images_flat)\n",
    "        latent_vectors.append(mu.cpu())\n",
    "        labels_list.append(labels)\n",
    "        \n",
    "        if len(latent_vectors) * images.size(0) >= 1000:  # Limit to 1000 samples\n",
    "            break\n",
    "\n",
    "latent_vectors = torch.cat(latent_vectors)\n",
    "labels_all = torch.cat(labels_list)\n",
    "\n",
    "print(f\"Latent vectors shape: {latent_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 2 dimensions of latent space\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], \n",
    "                     c=labels_all, cmap='tab10', alpha=0.6, edgecolors='k', s=20)\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('VAE Latent Space Visualization (First 2 Dimensions)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate between two random points in latent space\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample two random points\n",
    "    z1 = torch.randn(1, model.latent_dim).to(device)\n",
    "    z2 = torch.randn(1, model.latent_dim).to(device)\n",
    "    \n",
    "    # Interpolate\n",
    "    n_steps = 10\n",
    "    alphas = torch.linspace(0, 1, n_steps)\n",
    "    interpolated = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        z = (1 - alpha) * z1 + alpha * z2\n",
    "        sample = model.decode(z)\n",
    "        interpolated.append(sample.view(1, 1, 28, 28))\n",
    "    \n",
    "    interpolated = torch.cat(interpolated)\n",
    "\n",
    "# Plot interpolation\n",
    "fig, axes = plt.subplots(1, n_steps, figsize=(20, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(interpolated[i].cpu().squeeze(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{alphas[i]:.1f}')\n",
    "plt.suptitle('Latent Space Interpolation', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
